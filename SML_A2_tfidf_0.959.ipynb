{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "b6104f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up environment and list data files\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3653eb",
   "metadata": {},
   "source": [
    "## Load domain 1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "b9457150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain1 shape: (1000, 3)\n",
      "Label distribution in domain1:\n",
      " label\n",
      "0    500\n",
      "1    500\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[6, 22, 34, 76, 501, 977, 1, 2514, 13623, 76, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[222, 31, 4108, 104, 132, 361, 39, 2305, 12, 9...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[736, 7194, 113, 12, 366, 2870, 123, 101, 12, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[48, 1, 2025, 69, 361, 533, 327, 237, 4150, 13...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2973, 66, 1, 1493, 260, 2740, 50, 1027, 50, 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  id\n",
       "0  [6, 22, 34, 76, 501, 977, 1, 2514, 13623, 76, ...      0   0\n",
       "1  [222, 31, 4108, 104, 132, 361, 39, 2305, 12, 9...      0   1\n",
       "2  [736, 7194, 113, 12, 366, 2870, 123, 101, 12, ...      0   2\n",
       "3  [48, 1, 2025, 69, 361, 533, 327, 237, 4150, 13...      0   3\n",
       "4  [2973, 66, 1, 1493, 260, 2740, 50, 1027, 50, 1...      0   4"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load domain1 JSON as newline-delimited JSON (JSON Lines)\n",
    "df1 = pd.read_json('/Users/zigeliang/Desktop/All/Data Science 2025S1/COMP90051/A2/comp-90051-2025-s-1-project-2/domain1_train_data.json', lines=True)\n",
    "print(\"Domain1 shape:\", df1.shape)\n",
    "print(\"Label distribution in domain1:\\n\", df1['label'].value_counts())\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7473ee0",
   "metadata": {},
   "source": [
    "## Load domain 2 data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "9a2bbd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain1 shape: (5000, 3)\n",
      "Label distribution in domain1:\n",
      " label\n",
      "1    4750\n",
      "0     250\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[22, 6065, 76, 119, 13027, 575, 219, 22, 2435,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1275, 1509, 12, 6113, 6287, 327, 411, 1139, 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[575, 2962, 529, 4624, 39, 279, 1012, 277, 76,...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[12, 6113, 2428, 69, 375, 1025, 2605, 76, 101,...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[529, 76, 1509, 861, 1, 645, 1, 5013, 237, 3, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  id\n",
       "0  [22, 6065, 76, 119, 13027, 575, 219, 22, 2435,...      0   0\n",
       "1  [1275, 1509, 12, 6113, 6287, 327, 411, 1139, 2...      0   1\n",
       "2  [575, 2962, 529, 4624, 39, 279, 1012, 277, 76,...      0   2\n",
       "3  [12, 6113, 2428, 69, 375, 1025, 2605, 76, 101,...      0   3\n",
       "4  [529, 76, 1509, 861, 1, 645, 1, 5013, 237, 3, ...      0   4"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load domain1 JSON as newline-delimited JSON (JSON Lines)\n",
    "df2 = pd.read_json('/Users/zigeliang/Desktop/All/Data Science 2025S1/COMP90051/A2/comp-90051-2025-s-1-project-2/domain2_train_data.json', lines=True)\n",
    "print(\"Domain1 shape:\", df2.shape)\n",
    "print(\"Label distribution in domain1:\\n\", df2['label'].value_counts())\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaa9977",
   "metadata": {},
   "source": [
    "## Load the test dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "46836131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set shape: (4000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[9159, 3048, 238, 276, 162, 286, 305, 22, 36, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[64, 5039, 1275, 6, 0, 871, 139, 270, 327, 237...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[327, 618, 76, 650, 121, 274, 1025, 0, 12207, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[6, 12, 609, 11905, 4, 879, 677, 78, 13352, 60...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 5504, 55, 22, 101, 3783, 139, 2664, 4, 1, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  id\n",
       "0  [9159, 3048, 238, 276, 162, 286, 305, 22, 36, ...   0\n",
       "1  [64, 5039, 1275, 6, 0, 871, 139, 270, 327, 237...   1\n",
       "2  [327, 618, 76, 650, 121, 274, 1025, 0, 12207, ...   2\n",
       "3  [6, 12, 609, 11905, 4, 879, 677, 78, 13352, 60...   3\n",
       "4  [1, 5504, 55, 22, 101, 3783, 139, 2664, 4, 1, ...   4"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test JSON into a DataFrame and inspect\n",
    "df_test = pd.read_json('/Users/zigeliang/Desktop/All/Data Science 2025S1/COMP90051/A2/comp-90051-2025-s-1-project-2/test_data.json', lines=True)\n",
    "print(\"Test set shape:\", df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cbf302",
   "metadata": {},
   "source": [
    "## Combine domain 1 and domina 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "a15b9626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label  id   domain\n",
      "0  [6, 22, 34, 76, 501, 977, 1, 2514, 13623, 76, ...      0   0  domain1\n",
      "1  [222, 31, 4108, 104, 132, 361, 39, 2305, 12, 9...      0   1  domain1\n",
      "2  [736, 7194, 113, 12, 366, 2870, 123, 101, 12, ...      0   2  domain1\n",
      "3  [48, 1, 2025, 69, 361, 533, 327, 237, 4150, 13...      0   3  domain1\n",
      "4  [2973, 66, 1, 1493, 260, 2740, 50, 1027, 50, 1...      0   4  domain1\n",
      "Combined train shape: (6000, 4)\n",
      "\n",
      "Overall label distribution:\n",
      " label\n",
      "1    5250\n",
      "0     750\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Domain breakdown:\n",
      " domain\n",
      "domain2    5000\n",
      "domain1    1000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4541</th>\n",
       "      <td>[1, 5255, 377, 12598, 335, 2749, 101, 2239, 52...</td>\n",
       "      <td>1</td>\n",
       "      <td>3541</td>\n",
       "      <td>domain2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5057</th>\n",
       "      <td>[3882, 12, 5203, 5638, 10463, 206, 301, 12, 16...</td>\n",
       "      <td>1</td>\n",
       "      <td>4057</td>\n",
       "      <td>domain2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>[132, 6222, 151, 55, 48, 2436, 366, 13544, 13,...</td>\n",
       "      <td>1</td>\n",
       "      <td>807</td>\n",
       "      <td>domain1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3108</th>\n",
       "      <td>[353, 2606, 103, 353, 55, 838, 4, 1663, 1, 308...</td>\n",
       "      <td>1</td>\n",
       "      <td>2108</td>\n",
       "      <td>domain2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>[324, 151, 12, 316, 114, 510, 110, 1846, 235, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>741</td>\n",
       "      <td>domain2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label    id   domain\n",
       "4541  [1, 5255, 377, 12598, 335, 2749, 101, 2239, 52...      1  3541  domain2\n",
       "5057  [3882, 12, 5203, 5638, 10463, 206, 301, 12, 16...      1  4057  domain2\n",
       "807   [132, 6222, 151, 55, 48, 2436, 366, 13544, 13,...      1   807  domain1\n",
       "3108  [353, 2606, 103, 353, 55, 838, 4, 1663, 1, 308...      1  2108  domain2\n",
       "1741  [324, 151, 12, 316, 114, 510, 110, 1846, 235, ...      1   741  domain2"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine domain1 and domain2 into a single training DataFrame and inspect\n",
    "train = pd.concat([\n",
    "    df1.assign(domain='domain1'), # add a new column 'domain' with value 'domain1'\n",
    "    df2.assign(domain='domain2') # in the new added column called 'domain', mark the value from domain 2 with value 'domain2'\n",
    "], ignore_index=True)\n",
    "\n",
    "print(train.head())\n",
    "\n",
    "print(\"Combined train shape:\", train.shape)\n",
    "print(\"\\nOverall label distribution:\\n\", train['label'].value_counts())\n",
    "print(\"\\nDomain breakdown:\\n\", train['domain'].value_counts())\n",
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705bb5fc",
   "metadata": {},
   "source": [
    "## Method 1: Bag-of-Words + TF–IDF Baseline with Class-Weighted Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54108753",
   "metadata": {},
   "source": [
    "## Prepare text strings for TF-IDF input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "d50d278d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>domain</th>\n",
       "      <th>text_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>domain1</td>\n",
       "      <td>6 22 34 76 501 977 1 2514 13623 76 31 2085 277...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>domain1</td>\n",
       "      <td>222 31 4108 104 132 361 39 2305 12 936 1287 66...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>domain1</td>\n",
       "      <td>736 7194 113 12 366 2870 123 101 12 230 403 51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>domain1</td>\n",
       "      <td>48 1 2025 69 361 533 327 237 4150 13 22 2128 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>domain1</td>\n",
       "      <td>2973 66 1 1493 260 2740 50 1027 50 1 3289 69 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label   domain                                           text_str\n",
       "0   0      0  domain1  6 22 34 76 501 977 1 2514 13623 76 31 2085 277...\n",
       "1   1      0  domain1  222 31 4108 104 132 361 39 2305 12 936 1287 66...\n",
       "2   2      0  domain1  736 7194 113 12 366 2870 123 101 12 230 403 51...\n",
       "3   3      0  domain1  48 1 2025 69 361 533 327 237 4150 13 22 2128 1...\n",
       "4   4      0  domain1  2973 66 1 1493 260 2740 50 1027 50 1 3289 69 5..."
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert token sequences into strings\n",
    "train['text_str'] = train['text'].apply(lambda seq: ' '.join(map(str, seq)))\n",
    "df_test['text_str'] = df_test['text'].apply(lambda seq: ' '.join(map(str, seq)))\n",
    "\n",
    "train[['id', 'label', 'domain', 'text_str']].head() # inspect examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "2273c8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  label    id   domain  \\\n",
      "384   [1, 231, 3252, 22, 595, 4, 133, 101, 4, 1496, ...      0   384  domain1   \n",
      "3366  [13739, 3355, 101, 1, 73, 13, 22, 238, 706, 49...      1  2366  domain2   \n",
      "1218  [76, 1509, 55, 305, 497, 12, 1326, 69, 635, 80...      0   218  domain2   \n",
      "1312  [324, 151, 285, 3050, 1106, 1, 5971, 453, 69, ...      1   312  domain2   \n",
      "873   [1882, 12, 1773, 507, 36, 64, 12, 630, 39, 168...      1   873  domain1   \n",
      "\n",
      "                                               text_str  \n",
      "384   1 231 3252 22 595 4 133 101 4 1496 4613 12 702...  \n",
      "3366  13739 3355 101 1 73 13 22 238 706 496 12 2547 ...  \n",
      "1218  76 1509 55 305 497 12 1326 69 635 80 1 279 76 ...  \n",
      "1312  324 151 285 3050 1106 1 5971 453 69 852 39 143...  \n",
      "873   1882 12 1773 507 36 64 12 630 39 1685 164 324 ...  \n",
      "384     domain1\n",
      "3366    domain2\n",
      "1218    domain2\n",
      "1312    domain2\n",
      "873     domain1\n",
      "         ...   \n",
      "2487    domain2\n",
      "2047    domain2\n",
      "3718    domain2\n",
      "3856    domain2\n",
      "4606    domain2\n",
      "Name: domain, Length: 4800, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Split the combined DataFrame into df_train and df_val\n",
    "df_train, df_val = train_test_split(train, test_size=0.2, stratify = train['label'], random_state=42)\n",
    "\n",
    "print(df_train.head())\n",
    "print(df_train.domain)\n",
    "\n",
    "# Extract labels\n",
    "y_train = df_train['label'].values\n",
    "y_val   = df_val['label'].values\n",
    "\n",
    "# Fit TF-IDF on the training text_str\n",
    "vectorizer = TfidfVectorizer(max_features=15000)\n",
    "X_train_tf = vectorizer.fit_transform(df_train['text_str'])\n",
    "X_val_tf   = vectorizer.transform(df_val['text_str'])\n",
    "X_test_tf  = vectorizer.transform(df_test['text_str'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cacf5d",
   "metadata": {},
   "source": [
    "## Evulauate log-regression model baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "c0b17cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9250\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6546    0.8467    0.7384       150\n",
      "           1     0.9771    0.9362    0.9562      1050\n",
      "\n",
      "    accuracy                         0.9250      1200\n",
      "   macro avg     0.8159    0.8914    0.8473      1200\n",
      "weighted avg     0.9368    0.9250    0.9290      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate a class-weighted Logistic Regression baseline\n",
    "clf = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "\n",
    "# Fit on training TF-IDF features\n",
    "clf.fit(X_train_tf, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred = clf.predict(X_val_tf)\n",
    "\n",
    "# Evaluate\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "print(f\"Validation Accuracy: {acc:.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71238f20",
   "metadata": {},
   "source": [
    "## 5-Fold cross-validation of TF–IDF + logistic regression baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "85ace36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracies per fold: [0.9058 0.925  0.92   0.9133 0.9292]\n",
      "Mean CV accuracy: 0.9187 ± 0.0083\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=35000)),\n",
    "    ('clf',  LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Stratified 5-fold CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(\n",
    "    pipeline,\n",
    "    train['text_str'],\n",
    "    train['label'],\n",
    "    cv=cv,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"CV accuracies per fold:\", scores)\n",
    "print(f\"Mean CV accuracy: {scores.mean():.4f} ± {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66edb137",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning: GridSearchCV on TF–IDF + LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "dfb32943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "110 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 1.2102588701522097 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 1.4692812313906554 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 1.186354286473355 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 1.3380721211687647 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 1.083462587077464 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 1.1705656117958627 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 1.1167133569636 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 1.099273971544315 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 1.3408330340943375 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 1.0063108922680006 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 1.4450006544390532 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 1.4978184093491826 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 1.43483406730881 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 1.495281279818835 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 1.2975133507218395 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 1.3392549151366633 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 1.2398393142186397 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1102: UserWarning: One or more of the test scores are non-finite: [0.9242 0.9388    nan    nan    nan 0.9585 0.911     nan 0.9175    nan\n",
      "    nan    nan    nan    nan    nan    nan 0.9262    nan    nan 0.946\n",
      "    nan    nan    nan    nan    nan    nan 0.941     nan    nan    nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV Accuracy: 0.9585\n",
      "Best Parameters: {'clf__C': 1.3088706332961486, 'clf__penalty': None, 'tfidf__max_df': 0.6381795165788078, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# # param_grid for GridSearchCV\n",
    "# param_grid = {\n",
    "#     'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2), (1,3), (2,3), (3,3), (1,4)], # define the n-gram range\n",
    "#     'clf__C': [0.05, 0.1, 2, 3, 8],\n",
    "#     'clf__penalty': ['l1', 'l2', None], # l1 is for Lasso, l2 is for Ridge\n",
    "#     'tfidf__max_df': [0.5, 1.0], # max_df is the maximum document frequency\n",
    "#     'tfidf__min_df': [2, 5], # min_df is the minimum document frequency\n",
    "# }\n",
    "\n",
    "# param_grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2), (1, 3), (2, 3), (3, 3), (1, 4), (2, 4), (3, 4)],\n",
    "    'tfidf__max_df': uniform(loc=0.5, scale=1.0),  # samples from 0.5 to 1.5\n",
    "    'tfidf__min_df': [1, 2, 3, 5],\n",
    "    'clf__C': uniform(loc=0.01, scale=10),  # continuous range for C\n",
    "    'clf__penalty': ['l1', 'l2', None]\n",
    "} \n",
    "\n",
    "\n",
    "# # Perform grid search with GridSearchCV\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator= pipeline,\n",
    "#     param_grid= param_grid,\n",
    "#     cv= cv,\n",
    "#     scoring= 'accuracy',\n",
    "#     n_jobs= -1,\n",
    "#     verbose= 1\n",
    "# )\n",
    "\n",
    "# Perform grid search with RandomizedSearchCV\n",
    "grid_search = RandomizedSearchCV(\n",
    "    estimator = pipeline,\n",
    "    param_distributions = param_grid,\n",
    "    n_iter = 30,\n",
    "    cv= cv,\n",
    "    scoring= 'accuracy',\n",
    "    n_jobs= -1,\n",
    "    verbose= 1\n",
    ")\n",
    "\n",
    "# # why use tarin['text_str'] and train['label]\n",
    "# grid_search.fit(train['text_str'], train['label']) \n",
    "\n",
    "# # Perform grid search with GridSearchCV\n",
    "# grid_search.fit(df_train['text_str'], df_train['label'])\n",
    "\n",
    "\n",
    "# Perform grid search with RandomizedSearchCV\n",
    "grid_search.fit(df_train['text_str'], df_train['label'])\n",
    "\n",
    "print(\"Best CV Accuracy: {:.4f}\".format(grid_search.best_score_))\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21d25cc",
   "metadata": {},
   "source": [
    "### Re-evaluate model after hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "3736f0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hold-out Validation Accuracy: 0.9666666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9435    0.7800    0.8540       150\n",
      "           1     0.9693    0.9933    0.9812      1050\n",
      "\n",
      "    accuracy                         0.9667      1200\n",
      "   macro avg     0.9564    0.8867    0.9176      1200\n",
      "weighted avg     0.9661    0.9667    0.9653      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate tuned model on hold-out validation set\n",
    "best_pipe = grid_search.best_estimator_\n",
    "X_val_tuned = best_pipe.named_steps['tfidf'].transform(df_val['text_str'])\n",
    "y_val_pred = best_pipe.named_steps['clf'].predict(X_val_tuned)\n",
    "\n",
    "print(\"Hold-out Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(classification_report(y_val, y_val_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57af2000",
   "metadata": {},
   "source": [
    "## Threshold tuning for tuned TF–IDF + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "8c258d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold | Precision (human) | Recall (human) | F1 (human)\n",
      "  0.10    |   0.7702         |   0.8267     |  0.7974\n",
      "  0.15    |   0.7707         |   0.8067     |  0.7883\n",
      "  0.20    |   0.9160         |   0.8000     |  0.8541\n",
      "  0.25    |   0.9225         |   0.7933     |  0.8530\n",
      "  0.30    |   0.9360         |   0.7800     |  0.8509\n",
      "  0.35    |   0.9435         |   0.7800     |  0.8540\n",
      "  0.40    |   0.9435         |   0.7800     |  0.8540\n",
      "  0.45    |   0.9435         |   0.7800     |  0.8540\n",
      "  0.50    |   0.9435         |   0.7800     |  0.8540\n",
      "  0.55    |   0.9431         |   0.7733     |  0.8498\n",
      "  0.60    |   0.9431         |   0.7733     |  0.8498\n",
      "  0.65    |   0.9431         |   0.7733     |  0.8498\n",
      "  0.70    |   0.9431         |   0.7733     |  0.8498\n",
      "  0.75    |   0.9431         |   0.7733     |  0.8498\n",
      "  0.80    |   0.9426         |   0.7667     |  0.8456\n",
      "  0.85    |   0.9483         |   0.7333     |  0.8271\n",
      "  0.90    |   0.9558         |   0.7200     |  0.8213\n"
     ]
    }
   ],
   "source": [
    "best_pipe = grid_search.best_estimator_\n",
    "\n",
    "prob_human = best_pipe.predict_proba(df_val['text_str'])[:, 0]\n",
    "\n",
    "thresholds = np.linspace(0.1, 0.9, 17)\n",
    "print(\"Threshold | Precision (human) | Recall (human) | F1 (human)\")\n",
    "for t in thresholds:\n",
    "    preds = np.where(prob_human >= t, 0, 1)\n",
    "    # there is a higher chance of beinf a human (0) if prob_human >= t\n",
    "    prec = precision_score(y_val, preds, pos_label=0)\n",
    "    rec  = recall_score(y_val, preds, pos_label=0)\n",
    "    f1   = f1_score(y_val, preds, pos_label=0)\n",
    "    print(f\"  {t:.2f}    |   {prec:.4f}         |   {rec:.4f}     |  {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "c5f21fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_ngrom: (1, 2)\n",
      "Best_C: 1.3088706332961486\n",
      "Best_clf_penalty: None\n",
      "[0.     0.     1.     0.     0.     0.     0.     0.     1.     0.\n",
      " 0.     1.     0.     1.     0.     0.     0.     0.     0.     0.\n",
      " 0.     0.     0.     0.     0.     1.     0.     1.     0.     0.\n",
      " 0.     0.     1.     0.     0.     0.     0.     0.     0.     0.\n",
      " 0.     0.     0.     0.     0.     0.     0.     0.     0.4088 0.\n",
      " 0.     0.     0.     0.     0.    ]\n",
      "[1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Validation Accuracy (threshold = 0.65): 0.9667\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9583    0.7667    0.8519       150\n",
      "           1     0.9676    0.9952    0.9812      1050\n",
      "\n",
      "    accuracy                         0.9667      1200\n",
      "   macro avg     0.9630    0.8810    0.9165      1200\n",
      "weighted avg     0.9664    0.9667    0.9650      1200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_ngram = grid_search.best_params_['tfidf__ngram_range']\n",
    "print(f\"Best_ngrom: {best_ngram}\")\n",
    "\n",
    "best_C = grid_search.best_params_['clf__C']\n",
    "print(f\"Best_C: {best_C}\")\n",
    "\n",
    "best_clf_penalty = grid_search.best_params_['clf__penalty']\n",
    "print(f\"Best_clf_penalty: {best_clf_penalty}\")\n",
    "\n",
    "\n",
    "# Train a new pipeline with the best parameters\n",
    "pipeline_tuned = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features = 30000, ngram_range = best_ngram)),\n",
    "    ('clf',  LogisticRegression(class_weight='balanced', C=best_C, penalty=best_clf_penalty, max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the tuned pipeline on the training set\n",
    "pipeline_tuned.fit(df_train['text_str'], df_train['label'])\n",
    "\n",
    "# Predict on the validation set\n",
    "prob_human = pipeline_tuned.predict_proba(df_val['text_str'])[:, 0]\n",
    "\n",
    "print(prob_human[:55])\n",
    "\n",
    "threshold = 0.65\n",
    "preds_val = np.where(prob_human >= threshold, 0, 1)\n",
    "print(preds_val[:55])\n",
    "\n",
    "# Evaluate\n",
    "print(f\"Validation Accuracy (threshold = {threshold:.2f}): {accuracy_score(y_val, preds_val):.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, preds_val, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104f9a25",
   "metadata": {},
   "source": [
    "## Predict y based on the test file data and export as a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "82bd5e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob_human_test = pipeline_tuned.predict_proba(df_test['text_str'])[:, 0]\n",
    "# threshold_final = threshold\n",
    "# preds_test = np.where(prob_human_test >= threshold, 0, 1)\n",
    "\n",
    "# submission = pd.DataFrame({'id': df_test['id'], 'class': preds_test})\n",
    "# submission.to_csv('/Users/zigeliang/Desktop/All/Data Science 2025S1/COMP90051/A2/comp-90051-2025-s-1-project-2/tfidf2.csv', index=False)\n",
    "# submission.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4fbed7",
   "metadata": {},
   "source": [
    "## Method 2: SMOTE on Domain 2’s Human Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "d7d9aebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import vstack, csr_matrix\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "b6137ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE (Domain2 Human) Validation Accuracy: 0.9125\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.3000    0.4615       150\n",
      "           1     0.9091    1.0000    0.9524      1050\n",
      "\n",
      "    accuracy                         0.9125      1200\n",
      "   macro avg     0.9545    0.6500    0.7070      1200\n",
      "weighted avg     0.9205    0.9125    0.8910      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract TF–IDF vectorizer and optimal C from the tuned pipeline\n",
    "vectorizer = best_pipe.named_steps['tfidf']\n",
    "C_opt = best_pipe.named_steps['clf'].C\n",
    "\n",
    "# Transform train/validation into feature matrices\n",
    "X_train_all = vectorizer.transform(df_train['text_str'])\n",
    "X_val_tf    = vectorizer.transform(df_val['text_str'])\n",
    "y_train_all = df_train['label'].values\n",
    "\n",
    "# Select Domain 2 subset\n",
    "mask_dom2 = df_train['domain'] == 'domain2'\n",
    "X_dom2    = X_train_all[mask_dom2].toarray()\n",
    "y_dom2    = y_train_all[mask_dom2]\n",
    "\n",
    "# Apply SMOTE on Domain 2 human class (label 0)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_dom2_res, y_dom2_res = smote.fit_resample(X_dom2, y_dom2)\n",
    "\n",
    "# Re-combine with Domain 1 unchanged\n",
    "mask_dom1    = ~mask_dom2\n",
    "X_dom1       = X_train_all[mask_dom1]\n",
    "y_dom1       = y_train_all[mask_dom1]\n",
    "X_dom2_res_sp = csr_matrix(X_dom2_res)\n",
    "\n",
    "X_res = vstack([X_dom1, X_dom2_res_sp])\n",
    "y_res = np.concatenate([y_dom1, y_dom2_res])\n",
    "\n",
    "# Retrain Logistic Regression on SMOTE-augmented data\n",
    "clf_smote = LogisticRegression(class_weight='balanced',\n",
    "                               C=C_opt,\n",
    "                               max_iter=1000,\n",
    "                               random_state=42)\n",
    "clf_smote.fit(X_res, y_res)\n",
    "\n",
    "# Predict on validation using threshold = 0.70\n",
    "prob_hum_smote = clf_smote.predict_proba(X_val_tf)[:, 0]\n",
    "preds_smote    = np.where(prob_hum_smote >= 0.70, 0, 1)\n",
    "\n",
    "# Evaluate\n",
    "print(\"SMOTE (Domain2 Human) Validation Accuracy:\", accuracy_score(y_val, preds_smote))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, preds_smote, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32813fb9",
   "metadata": {},
   "source": [
    "##### Threshold tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "e0cc642c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold | Precision(0) | Recall(0) | F1(0)\n",
      "  0.10    |  0.2788   |   1.0000  |  0.4360\n",
      "  0.15    |  0.4233   |   0.9933  |  0.5936\n",
      "  0.20    |  0.5428   |   0.9733  |  0.6969\n",
      "  0.25    |  0.6227   |   0.9133  |  0.7405\n",
      "  0.30    |  0.6904   |   0.9067  |  0.7839\n",
      "  0.35    |  0.7288   |   0.8600  |  0.7890\n",
      "  0.40    |  0.8960   |   0.7467  |  0.8145\n",
      "  0.45    |  0.9479   |   0.6067  |  0.7398\n",
      "  0.50    |  0.9630   |   0.5200  |  0.6753\n",
      "  0.55    |  0.9848   |   0.4333  |  0.6019\n",
      "  0.60    |  0.9833   |   0.3933  |  0.5619\n",
      "  0.65    |  1.0000   |   0.3467  |  0.5149\n",
      "  0.70    |  1.0000   |   0.3000  |  0.4615\n",
      "  0.75    |  1.0000   |   0.2800  |  0.4375\n",
      "  0.80    |  1.0000   |   0.2533  |  0.4043\n",
      "  0.85    |  1.0000   |   0.1867  |  0.3146\n",
      "  0.90    |  1.0000   |   0.1533  |  0.2659\n"
     ]
    }
   ],
   "source": [
    "X_val_tf = vectorizer.transform(df_val['text_str'])\n",
    "\n",
    "# Get human-written probabilities from your SMOTE-trained classifier\n",
    "prob_human_smote = clf_smote.predict_proba(X_val_tf)[:, 0]\n",
    "\n",
    "# Sweep thresholds and report metrics for the human class\n",
    "thresholds = np.linspace(0.1, 0.9, 17)\n",
    "print(\"Threshold | Precision(0) | Recall(0) | F1(0)\")\n",
    "for t in thresholds:\n",
    "    preds = np.where(prob_human_smote >= t, 0, 1)\n",
    "    prec  = precision_score(y_val, preds, pos_label=0)\n",
    "    rec   = recall_score(y_val, preds, pos_label=0)\n",
    "    f1    = f1_score(y_val, preds, pos_label=0)\n",
    "    print(f\"  {t:.2f}    |  {prec:.4f}   |   {rec:.4f}  |  {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "a4ee4fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE Model Accuracy (threshold = 0.35): 0.9425\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7288    0.8600    0.7890       150\n",
      "           1     0.9795    0.9543    0.9667      1050\n",
      "\n",
      "    accuracy                         0.9425      1200\n",
      "   macro avg     0.8541    0.9071    0.8779      1200\n",
      "weighted avg     0.9481    0.9425    0.9445      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.35\n",
    "preds = np.where(prob_human_smote >= threshold, 0, 1)\n",
    "\n",
    "print(f\"SMOTE Model Accuracy (threshold = {threshold:.2f}):\",\n",
    "      accuracy_score(y_val, preds))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, preds, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7766841",
   "metadata": {},
   "source": [
    "## Predict y based on the test file data and export as a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "00af8db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_tf  = vectorizer.transform(df_test['text_str'])\n",
    "\n",
    "# prob_human_smote = clf_smote.predict_proba(X_test_tf)[:, 0]\n",
    "\n",
    "# preds_test = np.where(prob_human_smote >= 0.35, 0, 1)\n",
    "\n",
    "# submission_smote = pd.DataFrame({\n",
    "#     'id':    df_test['id'],\n",
    "#     'class': preds_test\n",
    "# })\n",
    "# submission_smote.to_csv('/Users/zigeliang/Desktop/All/Data Science 2025S1/COMP90051/A2/comp-90051-2025-s-1-project-2/smote_submission_tfidf2.csv', index=False)\n",
    "# submission_smote.head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729d23cc",
   "metadata": {},
   "source": [
    "## Method 3: Domain-Expert Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fd373e",
   "metadata": {},
   "source": [
    "#### Train domain-expert classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "f3b074cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain‐expert models trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Subset by domain\n",
    "train_dom1 = df_train[df_train.domain == 'domain1']\n",
    "train_dom2 = df_train[df_train.domain == 'domain2']\n",
    "\n",
    "\n",
    "# Define identical function for each domain\n",
    "pipe_dom1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features = 30000, ngram_range = best_ngram)),\n",
    "    ('clf',  LogisticRegression(class_weight='balanced', C = best_C, penalty=best_clf_penalty, max_iter= 1100, random_state=42))\n",
    "])\n",
    "\n",
    "pipe_dom2 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features = 30000, ngram_range = best_ngram)),\n",
    "    ('clf',  LogisticRegression(class_weight='balanced', C = best_C, penalty=best_clf_penalty, max_iter= 1100, random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "# Train\n",
    "pipe_dom1.fit(train_dom1.text_str, train_dom1.label)\n",
    "pipe_dom2.fit(train_dom2.text_str, train_dom2.label)\n",
    "\n",
    "print(\"Domain‐expert models trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da59a376",
   "metadata": {},
   "source": [
    "##### Evaluate domain-expert ensemble on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "a3de3d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Validation Accuracy (thr=0.70): 0.9841666666666666\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9852    0.8867    0.9333       150\n",
      "           1     0.9840    0.9981    0.9910      1050\n",
      "\n",
      "    accuracy                         0.9842      1200\n",
      "   macro avg     0.9846    0.9424    0.9622      1200\n",
      "weighted avg     0.9842    0.9842    0.9838      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Allocate an array for human-class probabilities\n",
    "probs = np.zeros(len(df_val))\n",
    "\n",
    "# Fill in per-domain probabilities\n",
    "mask_dom1 = df_val['domain'] == 'domain1'\n",
    "mask_dom2 = ~mask_dom1\n",
    "\n",
    "probs[mask_dom1] = pipe_dom1.predict_proba(df_val.loc[mask_dom1, 'text_str'])[:, 0]\n",
    "probs[mask_dom2] = pipe_dom2.predict_proba(df_val.loc[mask_dom2, 'text_str'])[:, 0]\n",
    "\n",
    "threshold = 0.70\n",
    "preds_ensemble = np.where(probs >= threshold, 0, 1)\n",
    "\n",
    "# Evaluate\n",
    "print(f\"Ensemble Validation Accuracy (thr={threshold:.2f}):\",\n",
    "      accuracy_score(y_val, preds_ensemble))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, preds_ensemble, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edbc1d0",
   "metadata": {},
   "source": [
    "## Threshold sweep for domain-expert ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "5ed6ffb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold | Precision(0) | Recall(0) | F1(0)\n",
      "  0.10    |   0.9375     |   0.9000   |  0.9184\n",
      "  0.15    |   0.9441     |   0.9000   |  0.9215\n",
      "  0.20    |   0.9507     |   0.9000   |  0.9247\n",
      "  0.25    |   0.9574     |   0.9000   |  0.9278\n",
      "  0.30    |   0.9574     |   0.9000   |  0.9278\n",
      "  0.35    |   0.9574     |   0.9000   |  0.9278\n",
      "  0.40    |   0.9643     |   0.9000   |  0.9310\n",
      "  0.45    |   0.9643     |   0.9000   |  0.9310\n",
      "  0.50    |   0.9643     |   0.9000   |  0.9310\n",
      "  0.55    |   0.9643     |   0.9000   |  0.9310\n",
      "  0.60    |   0.9710     |   0.8933   |  0.9306\n",
      "  0.65    |   0.9710     |   0.8933   |  0.9306\n",
      "  0.70    |   0.9852     |   0.8867   |  0.9333\n",
      "  0.75    |   0.9852     |   0.8867   |  0.9333\n",
      "  0.80    |   0.9851     |   0.8800   |  0.9296\n",
      "  0.85    |   0.9850     |   0.8733   |  0.9258\n",
      "  0.90    |   0.9846     |   0.8533   |  0.9143\n"
     ]
    }
   ],
   "source": [
    "# Compute ensemble “human” probabilities\n",
    "probs = np.zeros(len(df_val))\n",
    "mask_dom1     = df_val['domain'] == 'domain1'\n",
    "mask_dom2     = ~mask_dom1\n",
    "probs[mask_dom1] = pipe_dom1.predict_proba(df_val.loc[mask_dom1, 'text_str'])[:, 0]\n",
    "probs[mask_dom2] = pipe_dom2.predict_proba(df_val.loc[mask_dom2, 'text_str'])[:, 0]\n",
    "\n",
    "# Sweep thresholds\n",
    "thresholds = np.linspace(0.1, 0.9, 17)\n",
    "print(\"Threshold | Precision(0) | Recall(0) | F1(0)\")\n",
    "for t in thresholds:\n",
    "    preds = np.where(probs >= t, 0, 1)\n",
    "    prec  = precision_score(y_val, preds, pos_label=0)\n",
    "    rec   = recall_score(   y_val, preds, pos_label=0)\n",
    "    f1    = f1_score(       y_val, preds, pos_label=0)\n",
    "    print(f\"  {t:.2f}    |   {prec:.4f}     |   {rec:.4f}   |  {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1331e6c6",
   "metadata": {},
   "source": [
    "#### Evaluate ensemble based attempts of different thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "71423e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4929    False\n",
      "958      True\n",
      "1243    False\n",
      "1766    False\n",
      "2509    False\n",
      "        ...  \n",
      "5071    False\n",
      "2746    False\n",
      "5895    False\n",
      "2826    False\n",
      "1669    False\n",
      "Name: domain, Length: 1200, dtype: bool\n",
      "[1.1958e-09 0.0000e+00 1.0000e+00 7.7828e-09 4.7758e-07 1.7055e-08\n",
      " 6.2616e-03 2.5782e-07 1.0000e+00 3.1706e-07 2.0825e-09 1.0000e+00\n",
      " 3.5381e-09 6.6684e-01 2.2781e-08 9.9012e-09 1.9537e-07 4.6507e-09\n",
      " 7.7761e-09 9.7300e-13 1.2758e-09 7.3330e-09 4.1300e-13 2.7721e-09\n",
      " 1.8569e-10 1.0000e+00 5.7490e-05 1.0000e+00 1.7833e-08 1.6078e-08\n",
      " 2.4763e-08 4.0181e-10 1.0000e+00 3.3183e-10 2.0650e-13 1.5193e-07\n",
      " 9.2317e-07 3.6859e-11 2.5010e-08 3.1189e-07 0.0000e+00 0.0000e+00\n",
      " 1.0790e-09 1.8690e-07 1.0299e-06 4.9545e-06 1.6923e-09 2.8826e-12\n",
      " 1.0000e+00 3.7800e-07 0.0000e+00 1.7771e-11 1.0886e-08 1.0190e-07\n",
      " 2.1715e-10]\n",
      "Ensemble Validation Accuracy (threshold = 0.35): 0.9825\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9574    0.9000    0.9278       150\n",
      "           1     0.9858    0.9943    0.9900      1050\n",
      "\n",
      "    accuracy                         0.9825      1200\n",
      "   macro avg     0.9716    0.9471    0.9589      1200\n",
      "weighted avg     0.9823    0.9825    0.9823      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "probs = np.zeros(len(df_val)) \n",
    "mask_dom1 = df_val['domain'] == 'domain1'\n",
    "print(mask_dom1)\n",
    "mask_dom2 = ~mask_dom1\n",
    "# probs that the data from domain 1 is human-written\n",
    "probs[mask_dom1] = pipe_dom1.predict_proba(df_val.loc[mask_dom1, 'text_str'])[:, 0]\n",
    "# probs that the data from domain 2 is human-written\n",
    "probs[mask_dom2] = pipe_dom2.predict_proba(df_val.loc[mask_dom2, 'text_str'])[:, 0]\n",
    "\n",
    "print(probs[:55])\n",
    "\n",
    "# 2. Apply threshold\n",
    "# when the threshold is too high such as 0.75 and 0.80, even though the precision might be high like 98%\\\n",
    "# but the accuracy will be low, because of the overfitting. Therfore, the threshold should be set to 0.40 or 0.35\n",
    "threshold = 0.35 \n",
    "preds_ensem = np.where(probs >= threshold, 0, 1)\n",
    "\n",
    "\n",
    "# 3. Evaluate\n",
    "print(f\"Ensemble Validation Accuracy (threshold = {threshold:.2f}):\",\n",
    "      accuracy_score(y_val, preds_ensem))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, preds_ensem, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a177aa2",
   "metadata": {},
   "source": [
    "## Check for overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "ab056a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Training Accuracy (thr=0.40): 0.9997916666666666\n",
      "\n",
      "Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9983    1.0000    0.9992       600\n",
      "           1     1.0000    0.9998    0.9999      4200\n",
      "\n",
      "    accuracy                         0.9998      4800\n",
      "   macro avg     0.9992    0.9999    0.9995      4800\n",
      "weighted avg     0.9998    0.9998    0.9998      4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute “human” probabilities on the training split\n",
    "probs_train = np.zeros(len(df_train))\n",
    "mask_tr_dom1 = df_train['domain'] == 'domain1'\n",
    "mask_tr_dom2 = ~mask_tr_dom1\n",
    "\n",
    "probs_train[mask_tr_dom1] = pipe_dom1.predict_proba(df_train.loc[mask_tr_dom1, 'text_str'])[:, 0]\n",
    "probs_train[mask_tr_dom2] = pipe_dom2.predict_proba(df_train.loc[mask_tr_dom2, 'text_str'])[:, 0]\n",
    "\n",
    "threshold = 0.40\n",
    "preds_train = np.where(probs_train >= threshold, 0, 1)\n",
    "\n",
    "# Evaluate\n",
    "print(f\"Ensemble Training Accuracy (thr={threshold:.2f}):\",\n",
    "      accuracy_score(df_train['label'], preds_train))\n",
    "print(\"\\nTraining Classification Report:\")\n",
    "print(classification_report(df_train['label'], preds_train, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "4061ff51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  class\n",
       "0    0      0\n",
       "1    1      0\n",
       "2    2      0\n",
       "3    3      1\n",
       "4    4      0\n",
       "5    5      1\n",
       "6    6      0\n",
       "7    7      1\n",
       "8    8      0\n",
       "9    9      1\n",
       "10  10      0\n",
       "11  11      0\n",
       "12  12      0\n",
       "13  13      0\n",
       "14  14      0"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load & prepare test\n",
    "df_test = pd.read_json('/Users/zigeliang/Desktop/All/Data Science 2025S1/COMP90051/A2/comp-90051-2025-s-1-project-2/test_data.json', lines=True)\n",
    "df_test['text_str'] = df_test['text'].apply(lambda seq: ' '.join(map(str, seq)))\n",
    "\n",
    "# Get human‐class probs from both domain‐expert models\n",
    "p1 = pipe_dom1.predict_proba(df_test['text_str'])[:,0]\n",
    "p2 = pipe_dom2.predict_proba(df_test['text_str'])[:,0]\n",
    "\n",
    "probs_test = (p1 + p2) / 2\n",
    "\n",
    "threshold_final = threshold\n",
    "preds_test = np.where(probs_test >= threshold, 0, 1)\n",
    "\n",
    "submission = pd.DataFrame({'id': df_test['id'], 'class': preds_test})\n",
    "submission.to_csv('/Users/zigeliang/Desktop/All/Data Science 2025S1/COMP90051/A2/comp-90051-2025-s-1-project-2/smote_submission_tfidf2.csv', index=False)\n",
    "submission.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef5287e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03fcaf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
