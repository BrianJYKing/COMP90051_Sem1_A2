{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8002a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up environment and list data files\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_dir = r\"C:\\Users\\brian\\Documents\\UniMelb\\Year 2\\Semester 1\\COMP90051 Statistical Machine Learning\\Assignments\\Assignment 2\\comp-90051-2025-s-1-project-2\"\n",
    "os.chdir(data_dir)\n",
    "\n",
    "print(\"Working directory:\", os.getcwd())\n",
    "print(\"Files in folder:\", os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f648bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load domain1 JSON as newline-delimited JSON (JSON Lines)\n",
    "df1 = pd.read_json('domain1_train_data.json', lines=True)\n",
    "print(\"Domain1 shape:\", df1.shape)\n",
    "print(\"Label distribution in domain1:\\n\", df1['label'].value_counts())\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82293e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load domain2 JSON and inspect\n",
    "df2 = pd.read_json('domain2_train_data.json', lines=True)\n",
    "print(\"Domain2 shape:\", df2.shape)\n",
    "print(\"Label distribution in domain2:\\n\", df2['label'].value_counts())\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b74ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample submission CSV to inspect its format\n",
    "sample = pd.read_csv('sample.csv')\n",
    "print(\"Sample submission shape:\", sample.shape)\n",
    "print(\"\\nColumn types:\\n\", sample.dtypes)\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5436d483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test JSON into a DataFrame and inspect\n",
    "df_test = pd.read_json('test_data.json', lines=True)\n",
    "print(\"Test set shape:\", df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8ca108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine domain1 and domain2 into a single training DataFrame and inspect\n",
    "train = pd.concat([\n",
    "    df1.assign(domain='domain1'),\n",
    "    df2.assign(domain='domain2')\n",
    "], ignore_index=True)\n",
    "\n",
    "print(\"Combined train shape:\", train.shape)\n",
    "print(\"\\nOverall label distribution:\\n\", train['label'].value_counts())\n",
    "print(\"\\nDomain breakdown:\\n\", train['domain'].value_counts())\n",
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f825160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "%matplotlib inline\n",
    "\n",
    "# add a length column\n",
    "train['length'] = train['text'].apply(len)\n",
    "\n",
    "# summary statistics\n",
    "print(\"Length stats:\\n\", train['length'].describe())\n",
    "\n",
    "# histogram\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(train['length'], bins=50)\n",
    "plt.xlabel('Sequence length (tokens)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Training Data Sequence Length Distribution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991f885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad/truncate sequences to a fixed length\n",
    "# Choose MAX_LEN = 90 to cover ~95% of your data (only a few sequences > 90 tokens)\n",
    "MAX_LEN = 90\n",
    "PAD_VALUE = 0\n",
    "\n",
    "def pad_truncate(seq, max_len=MAX_LEN, pad_value=PAD_VALUE):\n",
    "    if len(seq) > max_len:\n",
    "        return seq[:max_len]\n",
    "    return seq + [pad_value] * (max_len - len(seq))\n",
    "\n",
    "# apply to train & test\n",
    "X_train = np.array(train['text'].apply(pad_truncate).tolist())\n",
    "X_test  = np.array(df_test['text'].apply(pad_truncate).tolist())\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test  shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6d7fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare labels, split into train/validation, and compute vocabulary size\n",
    "# labels\n",
    "y = train['label'].values\n",
    "\n",
    "# stratified split: 80% train, 20% validation\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "    X_train, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# vocab size: highest token ID + 1\n",
    "vocab_size = int(X_train.max() + 1)\n",
    "\n",
    "print(\"Training set:\", X_train_split.shape, y_train_split.shape)\n",
    "print(\"Validation set:\", X_val.shape, y_val.shape)\n",
    "print(\"Vocabulary size:\", vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a64df7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert token sequences into space-delimited strings for scikit-learn\n",
    "train['text_str'] = train['text'].apply(lambda seq: ' '.join(map(str, seq)))\n",
    "df_test['text_str'] = df_test['text'].apply(lambda seq: ' '.join(map(str, seq)))\n",
    "\n",
    "train[['id', 'label', 'domain', 'text_str']].head() # insepct examples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
