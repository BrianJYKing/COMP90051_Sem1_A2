{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6104f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up environment and list data files\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3653eb",
   "metadata": {},
   "source": [
    "## Load domain 1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9457150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain1 shape: (1000, 3)\n",
      "Label distribution in domain1:\n",
      " label\n",
      "0    500\n",
      "1    500\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[6, 22, 34, 76, 501, 977, 1, 2514, 13623, 76, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[222, 31, 4108, 104, 132, 361, 39, 2305, 12, 9...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[736, 7194, 113, 12, 366, 2870, 123, 101, 12, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[48, 1, 2025, 69, 361, 533, 327, 237, 4150, 13...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2973, 66, 1, 1493, 260, 2740, 50, 1027, 50, 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  id\n",
       "0  [6, 22, 34, 76, 501, 977, 1, 2514, 13623, 76, ...      0   0\n",
       "1  [222, 31, 4108, 104, 132, 361, 39, 2305, 12, 9...      0   1\n",
       "2  [736, 7194, 113, 12, 366, 2870, 123, 101, 12, ...      0   2\n",
       "3  [48, 1, 2025, 69, 361, 533, 327, 237, 4150, 13...      0   3\n",
       "4  [2973, 66, 1, 1493, 260, 2740, 50, 1027, 50, 1...      0   4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load domain1 JSON as newline-delimited JSON (JSON Lines)\n",
    "df1 = pd.read_json('/Users/zigeliang/Desktop/All/Data Science 2025S1/COMP90051/A2/comp-90051-2025-s-1-project-2/domain1_train_data.json', lines=True)\n",
    "print(\"Domain1 shape:\", df1.shape)\n",
    "print(\"Label distribution in domain1:\\n\", df1['label'].value_counts())\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7473ee0",
   "metadata": {},
   "source": [
    "## Load domain 2 data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a2bbd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain1 shape: (5000, 3)\n",
      "Label distribution in domain1:\n",
      " label\n",
      "1    4750\n",
      "0     250\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[22, 6065, 76, 119, 13027, 575, 219, 22, 2435,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1275, 1509, 12, 6113, 6287, 327, 411, 1139, 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[575, 2962, 529, 4624, 39, 279, 1012, 277, 76,...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[12, 6113, 2428, 69, 375, 1025, 2605, 76, 101,...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[529, 76, 1509, 861, 1, 645, 1, 5013, 237, 3, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  id\n",
       "0  [22, 6065, 76, 119, 13027, 575, 219, 22, 2435,...      0   0\n",
       "1  [1275, 1509, 12, 6113, 6287, 327, 411, 1139, 2...      0   1\n",
       "2  [575, 2962, 529, 4624, 39, 279, 1012, 277, 76,...      0   2\n",
       "3  [12, 6113, 2428, 69, 375, 1025, 2605, 76, 101,...      0   3\n",
       "4  [529, 76, 1509, 861, 1, 645, 1, 5013, 237, 3, ...      0   4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load domain1 JSON as newline-delimited JSON (JSON Lines)\n",
    "df2 = pd.read_json('/Users/zigeliang/Desktop/All/Data Science 2025S1/COMP90051/A2/comp-90051-2025-s-1-project-2/domain2_train_data.json', lines=True)\n",
    "print(\"Domain1 shape:\", df2.shape)\n",
    "print(\"Label distribution in domain1:\\n\", df2['label'].value_counts())\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaa9977",
   "metadata": {},
   "source": [
    "## Load the test dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46836131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set shape: (4000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[9159, 3048, 238, 276, 162, 286, 305, 22, 36, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[64, 5039, 1275, 6, 0, 871, 139, 270, 327, 237...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[327, 618, 76, 650, 121, 274, 1025, 0, 12207, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[6, 12, 609, 11905, 4, 879, 677, 78, 13352, 60...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 5504, 55, 22, 101, 3783, 139, 2664, 4, 1, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  id\n",
       "0  [9159, 3048, 238, 276, 162, 286, 305, 22, 36, ...   0\n",
       "1  [64, 5039, 1275, 6, 0, 871, 139, 270, 327, 237...   1\n",
       "2  [327, 618, 76, 650, 121, 274, 1025, 0, 12207, ...   2\n",
       "3  [6, 12, 609, 11905, 4, 879, 677, 78, 13352, 60...   3\n",
       "4  [1, 5504, 55, 22, 101, 3783, 139, 2664, 4, 1, ...   4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test JSON into a DataFrame and inspect\n",
    "df_test = pd.read_json('/Users/zigeliang/Desktop/All/Data Science 2025S1/COMP90051/A2/comp-90051-2025-s-1-project-2/test_data.json', lines=True)\n",
    "print(\"Test set shape:\", df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cbf302",
   "metadata": {},
   "source": [
    "## Combine domain 1 and domina 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a15b9626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined train shape: (6000, 4)\n",
      "\n",
      "Overall label distribution:\n",
      " label\n",
      "1    5250\n",
      "0     750\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Domain breakdown:\n",
      " domain\n",
      "domain2    5000\n",
      "domain1    1000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4403</th>\n",
       "      <td>[199, 22, 2085, 139, 12, 773, 76, 235, 4749, 2...</td>\n",
       "      <td>1</td>\n",
       "      <td>3403</td>\n",
       "      <td>domain2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792</th>\n",
       "      <td>[139, 93, 3062, 1, 231, 388, 69, 12, 3830, 101...</td>\n",
       "      <td>1</td>\n",
       "      <td>1792</td>\n",
       "      <td>domain2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5412</th>\n",
       "      <td>[9327, 180, 469, 1125, 677, 2158, 1679, 105, 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>4412</td>\n",
       "      <td>domain2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2619</th>\n",
       "      <td>[11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>1619</td>\n",
       "      <td>domain2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>[324, 151, 285, 241, 4, 7181, 664, 39, 831, 32...</td>\n",
       "      <td>1</td>\n",
       "      <td>786</td>\n",
       "      <td>domain1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label    id   domain\n",
       "4403  [199, 22, 2085, 139, 12, 773, 76, 235, 4749, 2...      1  3403  domain2\n",
       "2792  [139, 93, 3062, 1, 231, 388, 69, 12, 3830, 101...      1  1792  domain2\n",
       "5412  [9327, 180, 469, 1125, 677, 2158, 1679, 105, 1...      1  4412  domain2\n",
       "2619  [11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 1...      1  1619  domain2\n",
       "786   [324, 151, 285, 241, 4, 7181, 664, 39, 831, 32...      1   786  domain1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine domain1 and domain2 into a single training DataFrame and inspect\n",
    "train = pd.concat([\n",
    "    df1.assign(domain='domain1'),\n",
    "    df2.assign(domain='domain2')\n",
    "], ignore_index=True)\n",
    "\n",
    "print(\"Combined train shape:\", train.shape)\n",
    "print(\"\\nOverall label distribution:\\n\", train['label'].value_counts())\n",
    "print(\"\\nDomain breakdown:\\n\", train['domain'].value_counts())\n",
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705bb5fc",
   "metadata": {},
   "source": [
    "## Method 1: Bag-of-Words + TF–IDF Baseline with Class-Weighted Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54108753",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare text strings for TF-IDF input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d50d278d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>domain</th>\n",
       "      <th>text_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>domain1</td>\n",
       "      <td>6 22 34 76 501 977 1 2514 13623 76 31 2085 277...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>domain1</td>\n",
       "      <td>222 31 4108 104 132 361 39 2305 12 936 1287 66...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>domain1</td>\n",
       "      <td>736 7194 113 12 366 2870 123 101 12 230 403 51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>domain1</td>\n",
       "      <td>48 1 2025 69 361 533 327 237 4150 13 22 2128 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>domain1</td>\n",
       "      <td>2973 66 1 1493 260 2740 50 1027 50 1 3289 69 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label   domain                                           text_str\n",
       "0   0      0  domain1  6 22 34 76 501 977 1 2514 13623 76 31 2085 277...\n",
       "1   1      0  domain1  222 31 4108 104 132 361 39 2305 12 936 1287 66...\n",
       "2   2      0  domain1  736 7194 113 12 366 2870 123 101 12 230 403 51...\n",
       "3   3      0  domain1  48 1 2025 69 361 533 327 237 4150 13 22 2128 1...\n",
       "4   4      0  domain1  2973 66 1 1493 260 2740 50 1027 50 1 3289 69 5..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert token sequences into strings\n",
    "train['text_str'] = train['text'].apply(lambda seq: ' '.join(map(str, seq)))\n",
    "df_test['text_str'] = df_test['text'].apply(lambda seq: ' '.join(map(str, seq)))\n",
    "\n",
    "train[['id', 'label', 'domain', 'text_str']].head() # inspect examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2273c8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the combined DataFrame into df_train and df_val\n",
    "df_train, df_val = train_test_split(train, test_size=0.2, stratify = train['label'], random_state=42)\n",
    "\n",
    "# Extract labels\n",
    "y_train = df_train['label'].values\n",
    "y_val   = df_val['label'].values\n",
    "\n",
    "# Fit TF-IDF on the training text_str\n",
    "vectorizer = TfidfVectorizer(max_features=15000)\n",
    "X_train_tf = vectorizer.fit_transform(df_train['text_str'])\n",
    "X_val_tf   = vectorizer.transform(df_val['text_str'])\n",
    "X_test_tf  = vectorizer.transform(df_test['text_str'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cacf5d",
   "metadata": {},
   "source": [
    "## Evulauate log-regression model baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0b17cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9250\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6546    0.8467    0.7384       150\n",
      "           1     0.9771    0.9362    0.9562      1050\n",
      "\n",
      "    accuracy                         0.9250      1200\n",
      "   macro avg     0.8159    0.8914    0.8473      1200\n",
      "weighted avg     0.9368    0.9250    0.9290      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate a class-weighted Logistic Regression baseline\n",
    "clf = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "\n",
    "# Fit on training TF-IDF features\n",
    "clf.fit(X_train_tf, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred = clf.predict(X_val_tf)\n",
    "\n",
    "# Evaluate\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "print(f\"Validation Accuracy: {acc:.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71238f20",
   "metadata": {},
   "source": [
    "## 5-Fold cross-validation of TF–IDF + logistic regression baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85ace36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracies per fold: [0.90583333 0.925      0.92       0.91333333 0.92916667]\n",
      "Mean CV accuracy: 0.9187 ± 0.0083\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=35000)),\n",
    "    ('clf',  LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Stratified 5-fold CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(\n",
    "    pipeline,\n",
    "    train['text_str'],\n",
    "    train['label'],\n",
    "    cv=cv,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"CV accuracies per fold:\", scores)\n",
    "print(f\"Mean CV accuracy: {scores.mean():.4f} ± {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66edb137",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning: GridSearchCV on TF–IDF + LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dfb32943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "85 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 1.3191270964373885 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 1.1392468775629827 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 1.4353463437631637 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 1.3635950899808114 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 1.1822253832911458 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 1.0616412376972373 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 1.3146653841831792 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 1.1790829145737018 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 1.1478012891188807 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 469, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 406, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got 1.255237732369285 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1102: UserWarning: One or more of the test scores are non-finite: [       nan 0.90479167 0.90479167        nan 0.886875          nan\n",
      " 0.91270833        nan        nan        nan 0.90479167        nan\n",
      "        nan        nan        nan 0.95020833 0.92479167        nan\n",
      "        nan 0.96166667 0.92395833 0.92666667 0.896875          nan\n",
      " 0.96333333        nan        nan        nan        nan 0.92145833]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV Accuracy: 0.9633\n",
      "Best Parameters: {'clf__C': 9.349625001373763, 'clf__penalty': None, 'tfidf__max_df': 0.7501309216972853, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 3)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# # param_grid for GridSearchCV\n",
    "# param_grid = {\n",
    "#     'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2), (1,3), (2,3), (3,3), (1,4)], # define the n-gram range\n",
    "#     'clf__C': [0.05, 0.1, 2, 3, 8],\n",
    "#     'clf__penalty': ['l1', 'l2', None], # l1 is for Lasso, l2 is for Ridge\n",
    "#     'tfidf__max_df': [0.5, 1.0], # max_df is the maximum document frequency\n",
    "#     'tfidf__min_df': [2, 5], # min_df is the minimum document frequency\n",
    "# }\n",
    "\n",
    "# param_grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2), (1, 3), (2, 3), (3, 3), (1, 4), (2, 4), (3, 4)],\n",
    "    'tfidf__max_df': uniform(loc=0.5, scale=1),  # samples from 0.5 to 1.5\n",
    "    'tfidf__min_df': [1, 2, 3, 5],\n",
    "    'clf__C': uniform(loc=0.01, scale=10),  # continuous range for C\n",
    "    'clf__penalty': ['l1', 'l2', None],\n",
    "} \n",
    "\n",
    "\n",
    "# # Perform grid search with GridSearchCV\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator= pipeline,\n",
    "#     param_grid= param_grid,\n",
    "#     cv= cv,\n",
    "#     scoring= 'accuracy',\n",
    "#     n_jobs= -1,\n",
    "#     verbose= 1\n",
    "# )\n",
    "\n",
    "# Perform grid search with RandomizedSearchCV\n",
    "grid_search = RandomizedSearchCV(\n",
    "    estimator= pipeline,\n",
    "    param_distributions= param_grid,\n",
    "    n_iter = 30,\n",
    "    cv= cv,\n",
    "    scoring= 'accuracy',\n",
    "    n_jobs= -1,\n",
    "    verbose= 1\n",
    ")\n",
    "\n",
    "# # why use tarin['text_str'] and train['label]\n",
    "# grid_search.fit(train['text_str'], train['label']) \n",
    "\n",
    "# # Perform grid search with GridSearchCV\n",
    "# grid_search.fit(df_train['text_str'], df_train['label'])\n",
    "\n",
    "\n",
    "# Perform grid search with RandomizedSearchCV\n",
    "grid_search.fit(df_train['text_str'], df_train['label'])\n",
    "\n",
    "print(\"Best CV Accuracy: {:.4f}\".format(grid_search.best_score_))\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21d25cc",
   "metadata": {},
   "source": [
    "### Re-evaluate model after hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3736f0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hold-out Validation Accuracy: 0.97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9318    0.8200    0.8723       150\n",
      "           1     0.9747    0.9914    0.9830      1050\n",
      "\n",
      "    accuracy                         0.9700      1200\n",
      "   macro avg     0.9533    0.9057    0.9277      1200\n",
      "weighted avg     0.9694    0.9700    0.9692      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate tuned model on hold-out validation set\n",
    "best_pipe = grid_search.best_estimator_\n",
    "X_val_tuned = best_pipe.named_steps['tfidf'].transform(df_val['text_str'])\n",
    "y_val_pred = best_pipe.named_steps['clf'].predict(X_val_tuned)\n",
    "\n",
    "print(\"Hold-out Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(classification_report(y_val, y_val_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57af2000",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Threshold tuning for tuned TF–IDF + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c258d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold | Precision (human) | Recall (human) | F1 (human)\n",
      "  0.10    |   0.7414         |   0.8600     |  0.7963\n",
      "  0.15    |   0.7544         |   0.8600     |  0.8037\n",
      "  0.20    |   0.7619         |   0.8533     |  0.8050\n",
      "  0.25    |   0.7619         |   0.8533     |  0.8050\n",
      "  0.30    |   0.9137         |   0.8467     |  0.8789\n",
      "  0.35    |   0.9130         |   0.8400     |  0.8750\n",
      "  0.40    |   0.9197         |   0.8400     |  0.8780\n",
      "  0.45    |   0.9191         |   0.8333     |  0.8741\n",
      "  0.50    |   0.9318         |   0.8200     |  0.8723\n",
      "  0.55    |   0.9313         |   0.8133     |  0.8683\n",
      "  0.60    |   0.9313         |   0.8133     |  0.8683\n",
      "  0.65    |   0.9302         |   0.8000     |  0.8602\n",
      "  0.70    |   0.9302         |   0.8000     |  0.8602\n",
      "  0.75    |   0.9370         |   0.7933     |  0.8592\n",
      "  0.80    |   0.9435         |   0.7800     |  0.8540\n",
      "  0.85    |   0.9583         |   0.7667     |  0.8519\n",
      "  0.90    |   0.9576         |   0.7533     |  0.8433\n"
     ]
    }
   ],
   "source": [
    "best_pipe = grid_search.best_estimator_\n",
    "\n",
    "prob_human = best_pipe.predict_proba(df_val['text_str'])[:, 0]\n",
    "\n",
    "thresholds = np.linspace(0.1, 0.9, 17)\n",
    "print(\"Threshold | Precision (human) | Recall (human) | F1 (human)\")\n",
    "for t in thresholds:\n",
    "    preds = np.where(prob_human >= t, 0, 1)\n",
    "    # there is a higher chance of beinf a human (0) if prob_human >= t\n",
    "    prec = precision_score(y_val, preds, pos_label=0)\n",
    "    rec  = recall_score(y_val, preds, pos_label=0)\n",
    "    f1   = f1_score(y_val, preds, pos_label=0)\n",
    "    print(f\"  {t:.2f}    |   {prec:.4f}         |   {rec:.4f}     |  {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c5f21fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_ngrom: (1, 3)\n",
      "Best_C: 9.349625001373763\n",
      "Best_clf_penalty: None\n",
      "Validation Accuracy (threshold = 0.70): 0.9658\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9431    0.7733    0.8498       150\n",
      "           1     0.9684    0.9933    0.9807      1050\n",
      "\n",
      "    accuracy                         0.9658      1200\n",
      "   macro avg     0.9558    0.8833    0.9153      1200\n",
      "weighted avg     0.9653    0.9658    0.9644      1200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_ngram = grid_search.best_params_['tfidf__ngram_range']\n",
    "print(f\"Best_ngrom: {best_ngram}\")\n",
    "\n",
    "best_C = grid_search.best_params_['clf__C']\n",
    "print(f\"Best_C: {best_C}\")\n",
    "\n",
    "best_clf_penalty = grid_search.best_params_['clf__penalty']\n",
    "print(f\"Best_clf_penalty: {best_clf_penalty}\")\n",
    "\n",
    "# Train a new pipeline with the best parameters\n",
    "pipeline_tuned = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features = 32000, ngram_range = best_ngram)),\n",
    "    ('clf',  LogisticRegression(class_weight='balanced', C=best_C, penalty=best_clf_penalty, max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the tuned pipeline on the training set\n",
    "pipeline_tuned.fit(df_train['text_str'], df_train['label'])\n",
    "\n",
    "# Predict on the validation set\n",
    "prob_human = pipeline_tuned.predict_proba(df_val['text_str'])[:, 0]\n",
    "\n",
    "threshold = 0.70\n",
    "preds_val = np.where(prob_human >= threshold, 0, 1)\n",
    "\n",
    "# Evaluate\n",
    "print(f\"Validation Accuracy (threshold = {threshold:.2f}): {accuracy_score(y_val, preds_val):.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, preds_val, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104f9a25",
   "metadata": {},
   "source": [
    "## Predict y based on the test file data and export as a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "82bd5e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob_human_test = pipeline_tuned.predict_proba(df_test['text_str'])[:, 0]\n",
    "# threshold_final = threshold\n",
    "# preds_test = np.where(prob_human_test >= threshold, 0, 1)\n",
    "\n",
    "# submission = pd.DataFrame({'id': df_test['id'], 'class': preds_test})\n",
    "# submission.to_csv('/Users/zigeliang/Desktop/All/Data Science 2025S1/COMP90051/A2/comp-90051-2025-s-1-project-2/tfidf2.csv', index=False)\n",
    "# submission.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4fbed7",
   "metadata": {},
   "source": [
    "## Method 2: SMOTE on Domain 2’s Human Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d7d9aebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import vstack, csr_matrix\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6137ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE (Domain2 Human) Validation Accuracy: 0.9325\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.4600    0.6301       150\n",
      "           1     0.9284    1.0000    0.9629      1050\n",
      "\n",
      "    accuracy                         0.9325      1200\n",
      "   macro avg     0.9642    0.7300    0.7965      1200\n",
      "weighted avg     0.9373    0.9325    0.9213      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract TF–IDF vectorizer and optimal C from the tuned pipeline\n",
    "vectorizer = best_pipe.named_steps['tfidf']\n",
    "C_opt = best_pipe.named_steps['clf'].C\n",
    "\n",
    "# Transform train/validation into feature matrices\n",
    "X_train_all = vectorizer.transform(df_train['text_str'])\n",
    "X_val_tf    = vectorizer.transform(df_val['text_str'])\n",
    "y_train_all = df_train['label'].values\n",
    "\n",
    "# Select Domain 2 subset\n",
    "mask_dom2 = df_train['domain'] == 'domain2'\n",
    "X_dom2    = X_train_all[mask_dom2].toarray()\n",
    "y_dom2    = y_train_all[mask_dom2]\n",
    "\n",
    "# Apply SMOTE on Domain 2 human class (label 0)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_dom2_res, y_dom2_res = smote.fit_resample(X_dom2, y_dom2)\n",
    "\n",
    "# Re-combine with Domain 1 unchanged\n",
    "mask_dom1    = ~mask_dom2\n",
    "X_dom1       = X_train_all[mask_dom1]\n",
    "y_dom1       = y_train_all[mask_dom1]\n",
    "X_dom2_res_sp = csr_matrix(X_dom2_res)\n",
    "\n",
    "X_res = vstack([X_dom1, X_dom2_res_sp])\n",
    "y_res = np.concatenate([y_dom1, y_dom2_res])\n",
    "\n",
    "# Retrain Logistic Regression on SMOTE-augmented data\n",
    "clf_smote = LogisticRegression(class_weight='balanced',\n",
    "                               C=C_opt,\n",
    "                               max_iter=1000,\n",
    "                               random_state=42)\n",
    "clf_smote.fit(X_res, y_res)\n",
    "\n",
    "# Predict on validation using threshold = 0.70\n",
    "prob_hum_smote = clf_smote.predict_proba(X_val_tf)[:, 0]\n",
    "preds_smote    = np.where(prob_hum_smote >= 0.70, 0, 1)\n",
    "\n",
    "# Evaluate\n",
    "print(\"SMOTE (Domain2 Human) Validation Accuracy:\", accuracy_score(y_val, preds_smote))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, preds_smote, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32813fb9",
   "metadata": {},
   "source": [
    "##### Threshold tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0cc642c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold | Precision(0) | Recall(0) | F1(0)\n",
      "  0.10    |  0.5526   |   0.9800  |  0.7067\n",
      "  0.15    |  0.6327   |   0.9533  |  0.7606\n",
      "  0.20    |  0.7136   |   0.9467  |  0.8138\n",
      "  0.25    |  0.7446   |   0.9133  |  0.8204\n",
      "  0.30    |  0.7644   |   0.8867  |  0.8210\n",
      "  0.35    |  0.9270   |   0.8467  |  0.8850\n",
      "  0.40    |  0.9496   |   0.7533  |  0.8401\n",
      "  0.45    |  0.9545   |   0.7000  |  0.8077\n",
      "  0.50    |  0.9608   |   0.6533  |  0.7778\n",
      "  0.55    |  0.9892   |   0.6133  |  0.7572\n",
      "  0.60    |  0.9888   |   0.5867  |  0.7364\n",
      "  0.65    |  1.0000   |   0.5133  |  0.6784\n",
      "  0.70    |  1.0000   |   0.4600  |  0.6301\n",
      "  0.75    |  1.0000   |   0.4133  |  0.5849\n",
      "  0.80    |  1.0000   |   0.3733  |  0.5437\n",
      "  0.85    |  1.0000   |   0.3333  |  0.5000\n",
      "  0.90    |  1.0000   |   0.3067  |  0.4694\n"
     ]
    }
   ],
   "source": [
    "X_val_tf = vectorizer.transform(df_val['text_str'])\n",
    "\n",
    "# Get human-written probabilities from your SMOTE-trained classifier\n",
    "prob_human_smote = clf_smote.predict_proba(X_val_tf)[:, 0]\n",
    "\n",
    "# Sweep thresholds and report metrics for the human class\n",
    "thresholds = np.linspace(0.1, 0.9, 17)\n",
    "print(\"Threshold | Precision(0) | Recall(0) | F1(0)\")\n",
    "for t in thresholds:\n",
    "    preds = np.where(prob_human_smote >= t, 0, 1)\n",
    "    prec  = precision_score(y_val, preds, pos_label=0)\n",
    "    rec   = recall_score(y_val, preds, pos_label=0)\n",
    "    f1    = f1_score(y_val, preds, pos_label=0)\n",
    "    print(f\"  {t:.2f}    |  {prec:.4f}   |   {rec:.4f}  |  {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a4ee4fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE Model Accuracy (threshold = 0.35): 0.9725\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9270    0.8467    0.8850       150\n",
      "           1     0.9784    0.9905    0.9844      1050\n",
      "\n",
      "    accuracy                         0.9725      1200\n",
      "   macro avg     0.9527    0.9186    0.9347      1200\n",
      "weighted avg     0.9719    0.9725    0.9720      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.35\n",
    "preds = np.where(prob_human_smote >= threshold, 0, 1)\n",
    "\n",
    "print(f\"SMOTE Model Accuracy (threshold = {threshold:.2f}):\",\n",
    "      accuracy_score(y_val, preds))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, preds, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7766841",
   "metadata": {},
   "source": [
    "## Predict y based on the test file data and export as a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00af8db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  class\n",
       "0    0      1\n",
       "1    1      0\n",
       "2    2      0\n",
       "3    3      1\n",
       "4    4      0\n",
       "5    5      1\n",
       "6    6      0\n",
       "7    7      1\n",
       "8    8      1\n",
       "9    9      1\n",
       "10  10      1\n",
       "11  11      0\n",
       "12  12      0\n",
       "13  13      0\n",
       "14  14      0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_test_tf  = vectorizer.transform(df_test['text_str'])\n",
    "\n",
    "# prob_human_smote = clf_smote.predict_proba(X_test_tf)[:, 0]\n",
    "\n",
    "# preds_test = np.where(prob_human_smote >= 0.35, 0, 1)\n",
    "\n",
    "# submission_smote = pd.DataFrame({\n",
    "#     'id':    df_test['id'],\n",
    "#     'class': preds_test\n",
    "# })\n",
    "# submission_smote.to_csv('/Users/zigeliang/Desktop/All/Data Science 2025S1/COMP90051/A2/comp-90051-2025-s-1-project-2/smote_submission_tfidf2.csv', index=False)\n",
    "# submission_smote.head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729d23cc",
   "metadata": {},
   "source": [
    "## Method 3: Domain-Expert Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fd373e",
   "metadata": {},
   "source": [
    "#### Train domain-expert classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f3b074cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain‐expert models trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Subset by domain\n",
    "train_dom1 = df_train[df_train.domain == 'domain1']\n",
    "train_dom2 = df_train[df_train.domain == 'domain2']\n",
    "\n",
    "\n",
    "# Define identical function for each domain\n",
    "pipe_dom1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features = 32000, ngram_range = best_ngram)),\n",
    "    ('clf',  LogisticRegression(class_weight='balanced', C=best_C, penalty=best_clf_penalty, max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "pipe_dom2 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features = 32000, ngram_range = best_ngram)),\n",
    "    ('clf',  LogisticRegression(class_weight='balanced', C=best_C, penalty=best_clf_penalty, max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "# Train\n",
    "pipe_dom1.fit(train_dom1.text_str, train_dom1.label)\n",
    "pipe_dom2.fit(train_dom2.text_str, train_dom2.label)\n",
    "\n",
    "print(\"Domain‐expert models trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da59a376",
   "metadata": {},
   "source": [
    "##### Evaluate domain-expert ensemble on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a3de3d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Validation Accuracy (thr=0.70): 0.9783333333333334\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9921    0.8333    0.9058       150\n",
      "           1     0.9767    0.9990    0.9878      1050\n",
      "\n",
      "    accuracy                         0.9783      1200\n",
      "   macro avg     0.9844    0.9162    0.9468      1200\n",
      "weighted avg     0.9786    0.9783    0.9775      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Allocate an array for human-class probabilities\n",
    "probs = np.zeros(len(df_val))\n",
    "\n",
    "# Fill in per-domain probabilities\n",
    "mask_dom1 = df_val['domain'] == 'domain1'\n",
    "mask_dom2 = ~mask_dom1\n",
    "\n",
    "probs[mask_dom1] = pipe_dom1.predict_proba(df_val.loc[mask_dom1, 'text_str'])[:, 0]\n",
    "probs[mask_dom2] = pipe_dom2.predict_proba(df_val.loc[mask_dom2, 'text_str'])[:, 0]\n",
    "\n",
    "threshold = 0.70\n",
    "preds_ensemble = np.where(probs >= threshold, 0, 1)\n",
    "\n",
    "# Evaluate\n",
    "print(f\"Ensemble Validation Accuracy (thr={threshold:.2f}):\",\n",
    "      accuracy_score(y_val, preds_ensemble))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, preds_ensemble, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edbc1d0",
   "metadata": {},
   "source": [
    "## Threshold sweep for domain-expert ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5ed6ffb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold | Precision(0) | Recall(0) | F1(0)\n",
      "  0.10    |   0.9437     |   0.8933   |  0.9178\n",
      "  0.15    |   0.9640     |   0.8933   |  0.9273\n",
      "  0.20    |   0.9781     |   0.8933   |  0.9338\n",
      "  0.25    |   0.9852     |   0.8867   |  0.9333\n",
      "  0.30    |   0.9852     |   0.8867   |  0.9333\n",
      "  0.35    |   0.9848     |   0.8667   |  0.9220\n",
      "  0.40    |   0.9848     |   0.8667   |  0.9220\n",
      "  0.45    |   0.9846     |   0.8533   |  0.9143\n",
      "  0.50    |   0.9845     |   0.8467   |  0.9104\n",
      "  0.55    |   0.9845     |   0.8467   |  0.9104\n",
      "  0.60    |   0.9845     |   0.8467   |  0.9104\n",
      "  0.65    |   0.9843     |   0.8333   |  0.9025\n",
      "  0.70    |   0.9921     |   0.8333   |  0.9058\n",
      "  0.75    |   0.9921     |   0.8333   |  0.9058\n",
      "  0.80    |   0.9921     |   0.8333   |  0.9058\n",
      "  0.85    |   0.9918     |   0.8067   |  0.8897\n",
      "  0.90    |   1.0000     |   0.7800   |  0.8764\n"
     ]
    }
   ],
   "source": [
    "# Compute ensemble “human” probabilities\n",
    "probs = np.zeros(len(df_val))\n",
    "mask_dom1     = df_val['domain'] == 'domain1'\n",
    "mask_dom2     = ~mask_dom1\n",
    "probs[mask_dom1] = pipe_dom1.predict_proba(df_val.loc[mask_dom1, 'text_str'])[:, 0]\n",
    "probs[mask_dom2] = pipe_dom2.predict_proba(df_val.loc[mask_dom2, 'text_str'])[:, 0]\n",
    "\n",
    "# Sweep thresholds\n",
    "thresholds = np.linspace(0.1, 0.9, 17)\n",
    "print(\"Threshold | Precision(0) | Recall(0) | F1(0)\")\n",
    "for t in thresholds:\n",
    "    preds = np.where(probs >= t, 0, 1)\n",
    "    prec  = precision_score(y_val, preds, pos_label=0)\n",
    "    rec   = recall_score(   y_val, preds, pos_label=0)\n",
    "    f1    = f1_score(       y_val, preds, pos_label=0)\n",
    "    print(f\"  {t:.2f}    |   {prec:.4f}     |   {rec:.4f}   |  {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1331e6c6",
   "metadata": {},
   "source": [
    "#### Evaluate ensemble based attempts of different thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "71423e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Validation Accuracy (threshold = 0.40): 0.9816666666666667\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9848    0.8667    0.9220       150\n",
      "           1     0.9813    0.9981    0.9896      1050\n",
      "\n",
      "    accuracy                         0.9817      1200\n",
      "   macro avg     0.9831    0.9324    0.9558      1200\n",
      "weighted avg     0.9817    0.9817    0.9812      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "probs = np.zeros(len(df_val))\n",
    "mask_dom1 = df_val['domain'] == 'domain1'\n",
    "mask_dom2 = ~mask_dom1\n",
    "probs[mask_dom1] = pipe_dom1.predict_proba(df_val.loc[mask_dom1, 'text_str'])[:, 0]\n",
    "probs[mask_dom2] = pipe_dom2.predict_proba(df_val.loc[mask_dom2, 'text_str'])[:, 0]\n",
    "\n",
    "# 2. Apply threshold\n",
    "threshold = 0.40\n",
    "preds_ensem = np.where(probs >= threshold, 0, 1)\n",
    "\n",
    "# 3. Evaluate\n",
    "print(f\"Ensemble Validation Accuracy (threshold = {threshold:.2f}):\",\n",
    "      accuracy_score(y_val, preds_ensem))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, preds_ensem, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4061ff51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  class\n",
       "0    0      0\n",
       "1    1      0\n",
       "2    2      0\n",
       "3    3      1\n",
       "4    4      0\n",
       "5    5      1\n",
       "6    6      0\n",
       "7    7      1\n",
       "8    8      0\n",
       "9    9      1\n",
       "10  10      1\n",
       "11  11      0\n",
       "12  12      0\n",
       "13  13      0\n",
       "14  14      0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load & prepare test\n",
    "df_test = pd.read_json('/Users/zigeliang/Desktop/All/Data Science 2025S1/COMP90051/A2/comp-90051-2025-s-1-project-2/test_data.json', lines=True)\n",
    "df_test['text_str'] = df_test['text'].apply(lambda seq: ' '.join(map(str, seq)))\n",
    "\n",
    "# Get human‐class probs from both domain‐expert models\n",
    "p1 = pipe_dom1.predict_proba(df_test['text_str'])[:,0]\n",
    "p2 = pipe_dom2.predict_proba(df_test['text_str'])[:,0]\n",
    "\n",
    "probs_test = (p1 + p2) / 2\n",
    "\n",
    "threshold = 0.40\n",
    "preds_test = np.where(probs_test >= threshold, 0, 1)\n",
    "\n",
    "submission = pd.DataFrame({'id': df_test['id'], 'class': preds_test})\n",
    "submission.to_csv('/Users/zigeliang/Desktop/All/Data Science 2025S1/COMP90051/A2/comp-90051-2025-s-1-project-2/smote_submission_tfidf2.csv', index=False)\n",
    "submission.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef5287e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03fcaf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
